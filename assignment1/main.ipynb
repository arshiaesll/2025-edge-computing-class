{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Convolutional Neural Networks (CNNs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch packages\n",
    "import torch\n",
    "import torchvision as torchv\n",
    "\n",
    "# Packages that are nice to have\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchv.datasets.MNIST(\n",
    "    root='./dataset/train',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchv.transforms.ToTensor()\n",
    ")\n",
    "test_dataset = torchv.datasets.MNIST(\n",
    "    root='./dataset/test',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchv.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and Split the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data into numpy arrays\n",
    "train_images = train_dataset.data.numpy()\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "test_images = test_dataset.data.numpy()\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "print(\n",
    "    f'Train Images: {train_images.shape}\\n' +\n",
    "    f'Train Labels: {train_labels.shape}\\n' +\n",
    "    f'Test Images: {test_images.shape}\\n' +\n",
    "    f'Test Labels: {test_labels.shape}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the train datasets into one big dataset\n",
    "all_images = np.concat([train_images, test_images])\n",
    "all_labels = np.concat([train_labels, test_labels])\n",
    "print(\n",
    "    f'All Images: {all_images.shape}\\n' +\n",
    "    f'All Labels: {all_labels.shape}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the large numpy array into smaller train, validation, and test splits\n",
    "choices = np.arange(len(all_labels))\n",
    "train_perc, val_perc, test_perc = (0.7, 0.2, 0.1)\n",
    "num_samples = len(all_labels)\n",
    "num_train = int(np.floor(num_samples * train_perc))\n",
    "num_val = int(np.floor(num_samples * val_perc))\n",
    "num_test = num_samples - num_train - num_val\n",
    "num_train, num_val, num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select indices throughout the whole dataset\n",
    "train_idx = np.random.choice(choices, num_train, replace=False)\n",
    "choices = np.setdiff1d(choices, train_idx)\n",
    "val_idx = np.random.choice(choices, num_val, replace=False)\n",
    "test_idx = np.setdiff1d(choices, val_idx)\n",
    "train_idx, val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure disjoint sets\n",
    "np.intersect1d(np.intersect1d(train_idx, val_idx), test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets\n",
    "train_images, train_labels = all_images[train_idx], all_labels[train_idx]\n",
    "val_images, val_labels = all_images[val_idx], all_labels[val_idx]\n",
    "test_images, test_labels = all_images[test_idx], all_labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image):\n",
    "    x = np.pad(image, pad_width=2)\n",
    "    x = np.reshape(x, (1, 32, 32))\n",
    "    x = torch.Tensor(x / 255.0)\n",
    "    return x\n",
    "\n",
    "\n",
    "def target_transform(label):\n",
    "    x = int(label)\n",
    "    return x\n",
    "\n",
    "\n",
    "class MNIST_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=transform, target_transform=target_transform):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(\n",
    "    train_images, train_labels, transform=transform, target_transform=target_transform)\n",
    "val_dataset = MNIST_Dataset(\n",
    "    val_images, val_labels, transform=transform, target_transform=target_transform)\n",
    "test_dataset = MNIST_Dataset(\n",
    "    test_images, test_labels, transform=transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram showing the frequency of each class in the dataset\n",
    "plt.hist(all_labels, bins=np.arange(11) - 0.5, edgecolor='black')\n",
    "plt.xticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencies of each class in the 3 separate datasets\n",
    "labels = np.unique(train_labels)\n",
    "plt.hist([train_labels, val_labels, test_labels])\n",
    "plt.xticks(labels)\n",
    "plt.legend(['Train', 'Val', 'Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying one sample of each class\n",
    "visualization_samples = []\n",
    "plt.subplot(2, 5, 1)\n",
    "for i in range(10):\n",
    "    indices = np.where(train_labels == i)[0]\n",
    "    rand_idx = indices[np.random.randint(0, len(indices) - 1)]\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(np.squeeze(train_images[rand_idx]))\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.title(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the CNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OGLeNet5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define the layers\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.avgpool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.avgpool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(400, 120)\n",
    "        self.linear2 = torch.nn.Linear(120, 84)\n",
    "        self.linear3 = torch.nn.Linear(84, out_features=NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.functional.F.tanh(x)\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.functional.F.tanh(x)\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.functional.F.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.functional.F.tanh(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Original LeNet-5 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_lenet5 = OGLeNet5()\n",
    "summary(original_lenet5, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModernLeNet5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define the layers\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(6)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(16)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(400, 120)\n",
    "        self.linear2 = torch.nn.Linear(120, 84)\n",
    "        self.linear3 = torch.nn.Linear(84, out_features=NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = torch.functional.F.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = torch.functional.F.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.functional.F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.functional.F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Modernized LeNet-5 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modern_lenet5 = ModernLeNet5()\n",
    "summary(modern_lenet5, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Loss Functions and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paremeters\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our loss function\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Setup an optimizer for each of the two models\n",
    "optim_original_lenet5 = torch.optim.Adam(\n",
    "    original_lenet5.parameters(), lr=LEARNING_RATE)\n",
    "optim_modern_lenet5 = torch.optim.Adam(\n",
    "    modern_lenet5.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    loss_function,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device\n",
    "):\n",
    "    # Total number batches in training set\n",
    "    total_steps = len(train_dataloader)\n",
    "\n",
    "    # Perform training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            # Move the data to the desired training device\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Perform the forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform the backwards pass (i.e. backpropogate the error)\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "\n",
    "            # Done with batch, print stats every 500 batches\n",
    "            if (i+1) % 500 == 0:\n",
    "                print(\n",
    "                    f'TRAINING --> Epoch: {epoch}/{num_epochs}, ' +\n",
    "                    f'Step: {i+1}/{total_steps}, ' +\n",
    "                    f'Loss: {loss.item()}'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the original version of LeNet5\n",
    "original_lenet5.to(DEVICE)\n",
    "train_model(train_dataloader, original_lenet5,\n",
    "            loss, optim_original_lenet5, NUM_EPOCHS, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the modern version of LeNet5\n",
    "modern_lenet5.to(DEVICE)\n",
    "train_model(train_dataloader, modern_lenet5,\n",
    "            loss, optim_modern_lenet5, NUM_EPOCHS, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
